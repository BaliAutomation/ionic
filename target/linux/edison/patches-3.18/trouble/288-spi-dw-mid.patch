diff --git a/drivers/spi/spi-dw-mid.c b/drivers/spi/spi-dw-mid.c
index b9f0192..54700a2 100644
--- a/drivers/spi/spi-dw-mid.c
+++ b/drivers/spi/spi-dw-mid.c
@@ -22,7 +22,6 @@
 #include <linux/interrupt.h>
 #include <linux/slab.h>
 #include <linux/spi/spi.h>
-#include <linux/types.h>
 
 #include "spi-dw.h"
 
@@ -55,6 +54,8 @@ static int mid_spi_dma_init(struct dw_spi *dws)
 	dws->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0813, NULL);
 	if (!dws->dmac)
 		dws->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0827, NULL);
+	if (!dws->dmac)
+		dws->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x08EF, NULL);
 
 	dma_cap_zero(mask);
 	dma_cap_set(DMA_SLAVE, mask);
@@ -111,8 +112,11 @@ static int mid_spi_dma_transfer(struct dw_spi *dws, int cs_change)
 {
 	struct dma_async_tx_descriptor *txdesc = NULL, *rxdesc = NULL;
 	struct dma_chan *txchan, *rxchan;
-	struct dma_slave_config txconf, rxconf;
+	struct dma_slave_config *txconf, *rxconf;
 	u16 dma_ctrl = 0;
+	enum dma_ctrl_flags flag;
+	struct device *dev = &dws->master->dev;
+	struct intel_mid_dma_slave *rxs, *txs;
 
 	/* 1. setup DMA related registers */
 	if (cs_change) {
@@ -131,51 +135,65 @@ static int mid_spi_dma_transfer(struct dw_spi *dws, int cs_change)
 	txchan = dws->txchan;
 	rxchan = dws->rxchan;
 
-	/* 2. Prepare the TX dma transfer */
-	txconf.direction = DMA_MEM_TO_DEV;
-	txconf.dst_addr = dws->dma_addr;
-	txconf.dst_maxburst = LNW_DMA_MSIZE_16;
-	txconf.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
-	txconf.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES;
-	txconf.device_fc = false;
+	txs = txchan->private;
+	rxs = rxchan->private;
 
-	txchan->device->device_control(txchan, DMA_SLAVE_CONFIG,
-				       (unsigned long) &txconf);
+	txconf = &txs->dma_slave;
+	rxconf = &rxs->dma_slave;
 
-	memset(&dws->tx_sgl, 0, sizeof(dws->tx_sgl));
-	dws->tx_sgl.dma_address = dws->tx_dma;
-	dws->tx_sgl.length = dws->len;
+	flag = DMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP | DMA_CTRL_ACK;
 
-	txdesc = dmaengine_prep_slave_sg(txchan,
-				&dws->tx_sgl,
-				1,
-				DMA_MEM_TO_DEV,
-				DMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP);
-	txdesc->callback = dw_spi_dma_done;
-	txdesc->callback_param = dws;
+	/* 2. Prepare the TX dma transfer */
+	txconf->direction = DMA_MEM_TO_DEV;
+	txconf->dst_addr = dws->dma_addr;
+	txconf->src_maxburst = LNW_DMA_MSIZE_16;
+	txconf->dst_maxburst = LNW_DMA_MSIZE_16;
+	txconf->src_addr_width = dws->dma_width;
+	txconf->dst_addr_width = dws->dma_width;
+	txconf->device_fc = false;
+
+	txchan->device->device_control(txchan, DMA_SLAVE_CONFIG,
+				       (unsigned long) txconf);
+
+	txdesc = txchan->device->device_prep_dma_memcpy
+		(txchan,			/* DMA Channel */
+		dws->dma_addr,			/* DAR */
+		dws->tx_dma,			/* SAR */
+		dws->len,			/* Data Length */
+		flag);
+	if (txdesc) {
+		txdesc->callback = dw_spi_dma_done;
+		txdesc->callback_param = dws;
+	} else {
+		dev_err(dev, "ERROR: prepare txdesc failed\n");
+		return -EINVAL;
+	}
 
 	/* 3. Prepare the RX dma transfer */
-	rxconf.direction = DMA_DEV_TO_MEM;
-	rxconf.src_addr = dws->dma_addr;
-	rxconf.src_maxburst = LNW_DMA_MSIZE_16;
-	rxconf.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
-	rxconf.src_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES;
-	rxconf.device_fc = false;
+	rxconf->direction = DMA_DEV_TO_MEM;
+	rxconf->src_addr = dws->dma_addr;
+	rxconf->src_maxburst = LNW_DMA_MSIZE_16;
+	rxconf->dst_maxburst = LNW_DMA_MSIZE_16;
+	rxconf->dst_addr_width = dws->dma_width;
+	rxconf->src_addr_width = dws->dma_width;
+	rxconf->device_fc = false;
 
 	rxchan->device->device_control(rxchan, DMA_SLAVE_CONFIG,
-				       (unsigned long) &rxconf);
-
-	memset(&dws->rx_sgl, 0, sizeof(dws->rx_sgl));
-	dws->rx_sgl.dma_address = dws->rx_dma;
-	dws->rx_sgl.length = dws->len;
-
-	rxdesc = dmaengine_prep_slave_sg(rxchan,
-				&dws->rx_sgl,
-				1,
-				DMA_DEV_TO_MEM,
-				DMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP);
-	rxdesc->callback = dw_spi_dma_done;
-	rxdesc->callback_param = dws;
+				       (unsigned long) rxconf);
+
+	rxdesc = rxchan->device->device_prep_dma_memcpy
+		(rxchan,			/* DMA Channel */
+		dws->rx_dma,			/* DAR */
+		dws->dma_addr,			/* SAR */
+		dws->len,			/* Data Length */
+		flag);
+	if (rxdesc) {
+		rxdesc->callback = dw_spi_dma_done;
+		rxdesc->callback_param = dws;
+	} else {
+		dev_err(dev, "ERROR: prepare rxdesc failed\n");
+		return -EINVAL;
+	}
 
 	/* rx must be started before tx due to spi instinct */
 	rxdesc->tx_submit(rxdesc);
@@ -183,10 +201,41 @@ static int mid_spi_dma_transfer(struct dw_spi *dws, int cs_change)
 	return 0;
 }
 
+static int mid_spi_dma_suspend(struct dw_spi *dws)
+{
+	struct dma_chan *txchan, *rxchan;
+
+	txchan = dws->txchan;
+	rxchan = dws->rxchan;
+
+	txchan->device->device_control(txchan, DMA_TERMINATE_ALL, 0);
+	rxchan->device->device_control(rxchan, DMA_TERMINATE_ALL, 0);
+
+	txchan->device->device_control(txchan, DMA_PAUSE, 0);
+	rxchan->device->device_control(rxchan, DMA_PAUSE, 0);
+
+	return 0;
+}
+
+static int mid_spi_dma_resume(struct dw_spi *dws)
+{
+	struct dma_chan *txchan, *rxchan;
+
+	txchan = dws->txchan;
+	rxchan = dws->rxchan;
+
+	txchan->device->device_control(txchan, DMA_RESUME, 0);
+	rxchan->device->device_control(rxchan, DMA_RESUME, 0);
+
+	return 0;
+}
+
 static struct dw_spi_dma_ops mid_dma_ops = {
 	.dma_init	= mid_spi_dma_init,
 	.dma_exit	= mid_spi_dma_exit,
 	.dma_transfer	= mid_spi_dma_transfer,
+	.dma_suspend	= mid_spi_dma_suspend,
+	.dma_resume	= mid_spi_dma_resume,
 };
 #endif
 
@@ -201,12 +250,12 @@ static struct dw_spi_dma_ops mid_dma_ops = {
 #define CLK_SPI_CDIV_MASK	0x00000e00
 #define CLK_SPI_DISABLE_OFFSET	8
 
-int dw_spi_mid_init(struct dw_spi *dws)
+int dw_spi_mid_init(struct dw_spi *dws, int bus_num)
 {
 	void __iomem *clk_reg;
 	u32 clk_cdiv;
 
-	clk_reg = ioremap_nocache(MRST_CLK_SPI0_REG, 16);
+	clk_reg = ioremap_nocache(MRST_CLK_SPI0_REG + bus_num * 4, 16);
 	if (!clk_reg)
 		return -ENOMEM;
 
